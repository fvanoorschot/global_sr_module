{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62e3f38f-c900-4727-a9e1-2735ae539100",
   "metadata": {},
   "source": [
    "# Main run script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9107eedc-c820-4eba-87b3-c52f84faf2fa",
   "metadata": {},
   "source": [
    "This script contains the main procedure to calculate global root zone storage capacities. \n",
    "\n",
    "This scripts only works in the conda environment **sr_env**. In this environment all required packages are available. If you have **not** installed and activated this environment before opening this script, you should check the installation section in the *README* file. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d86bf57-168c-4591-9050-c261b4adaafd",
   "metadata": {},
   "source": [
    "### 1. Getting started\n",
    "First, import all the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12476d9c-f4d9-41d7-889e-4e84ec7ee35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import calendar\n",
    "import geopandas as gpd\n",
    "import cartopy\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from pathos.threading import ThreadPool as Pool\n",
    "from scipy.optimize import least_squares\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import gaussian_kde\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools import add_constant\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d94080-a55a-49dc-bfd7-09ef86d1ffa2",
   "metadata": {},
   "source": [
    "Here we import all the python functions defined in the scripts *f_catch_characteristics.py* and *f_preprocess_discharge.py*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b053a7a-23b8-434d-ae1d-19888e5f5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python functions\n",
    "from f_catch_characteristics import *\n",
    "from f_preprocess_discharge import *\n",
    "from f_sr_calculation import *\n",
    "from f_regression import *\n",
    "from f_grid_to_catchments import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a9ed88-646a-4209-b0a1-5e01426119ee",
   "metadata": {},
   "source": [
    "### 2. Define working and data directories\n",
    "Here we define the working directory, where all the scripts and output are saved.\n",
    "\n",
    "We also define the data directory where you have the following subdirectories:\n",
    "\n",
    "/data/forcing/*netcdf forcing files*\\\n",
    "/data/shapes/*catchment shapefiles*\\\n",
    "/data/gsim_discharge/*gsim discharge timeseries*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e8fa1bc-52f6-4907-ac52-d181690a37a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/u/LSM root zone/global_sr/scripts/global_sr_module'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check current working directory (helpful when filling in work_dir below)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48e094df-ec04-4c83-a259-9a4395300ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your script working directory\n",
    "work_dir=Path(\"/mnt/u/LSM root zone/global_sr/\")\n",
    "# work_dir=Path('/tudelft.net/staff-umbrella/LSM root zone/global_sr')\n",
    "\n",
    "# define your data directory\n",
    "data_dir=Path(f'{work_dir}/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e725c95a-41c4-41ee-8e26-a2d21cecd45b",
   "metadata": {},
   "source": [
    "Here we create the output directory inside your working directory. In the remainder of this module, the same command will be used regularly to create directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28501b38-7d4c-4c8d-9e0a-237aa5605dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output directory\n",
    "if not os.path.exists(f'{work_dir}/output'):\n",
    "    os.makedirs(f'{work_dir}/output')\n",
    "out_dir = Path(f\"{work_dir}/output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e78deb3-3f08-44cc-b8d0-9b88e07afcad",
   "metadata": {},
   "source": [
    "### 2. GSIM discharge data\n",
    "### 2.1 Catchment id lists\n",
    "The GSIM discharge data contains yearly discharge files for ~30000 catchments. These files are stored here *{data_dir}/GSIM_data/GSIM_indices/TIMESERIES/yearly/* and origin from https://essd.copernicus.org/articles/10/765/2018/ and\n",
    "https://essd.copernicus.org/articles/10/787/2018/.\n",
    "Here we create lists of the catchment ids for later use, both with upper and lower characters. Files are saved in *out_dir/gsim/*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9e0fa0d-eaa1-421c-ab69-c1f4e8c015c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of all catchment ids available in the GSIM yearly discharge timeseries data\n",
    "gsim_id_list_up = []\n",
    "gsim_id_list_lo = []\n",
    "for filepath in glob.iglob(f'{data_dir}/GSIM_data/GSIM_indices/TIMESERIES/yearly/*'):\n",
    "    f = os.path.split(filepath)[1] # remove full path\n",
    "    f = f[:-5] # remove .year extension\n",
    "    fl = f.lower()\n",
    "    gsim_id_list_up.append(f)\n",
    "    gsim_id_list_lo.append(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4d2c34fb-33cc-4607-9c09-e725cd46d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{work_dir}/output/gsim'):\n",
    "    os.makedirs(f'{work_dir}/output/gsim')\n",
    "np.savetxt(f'{out_dir}/gsim/gsim_catch_id_list_up.txt',gsim_id_list_up,fmt='%s')\n",
    "np.savetxt(f'{out_dir}/gsim/gsim_catch_id_list_lo.txt',gsim_id_list_lo,fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5ad5a6-4a80-4876-b815-e22d0f4a1442",
   "metadata": {},
   "source": [
    "### 2.2 Preprocess data \n",
    "The GSIM yearly discharge timeseries are stored in *.year* files. A detailed explanation of the column names is provided in Table 3 and 4 in https://essd.copernicus.org/articles/10/787/2018/. Here we preprocess these data into readable *.csv* files for each catchment.\n",
    "\n",
    "The preprocessing function *preprocess_gsim_discharge* is defined in the file *f_preprocess_discharge.py*. With this function we generate for each catchment a file with the yearly discharge timeseries and a file with the specifications of the catchment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23ce5bd9-8f79-4a45-a598-04ddcb1d18fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output directories\n",
    "if not os.path.exists(f'{out_dir}/gsim/timeseries'):\n",
    "    os.makedirs(f'{out_dir}/gsim/timeseries')\n",
    "\n",
    "if not os.path.exists(f'{out_dir}/gsim/timeseries_selected'):\n",
    "    os.makedirs(f'{out_dir}/gsim/timeseries_selected')\n",
    "    \n",
    "if not os.path.exists(f'{out_dir}/gsim/characteristics'):\n",
    "    os.makedirs(f'{out_dir}/gsim/characteristics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e0041d-a369-47cd-afc7-69886d73cec6",
   "metadata": {},
   "source": [
    "Here we do a test run with only 5 catchments to reduce computational time. Run all catchments on Delftblue using slurm and the *run_gsim_preprocessing.py* script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b1495ea-6308-4d4d-ae77-8722d9683281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load catchment ids\n",
    "gsim_id_list_lo = np.loadtxt(f'{out_dir}/gsim/gsim_catch_id_list_lo.txt',dtype=str) \n",
    "\n",
    "# select randomly 5 catchments\n",
    "# gsim_id_list_lo = random.choices(gsim_id_list_lo,k=5)\n",
    "gsim_id_list_lo = gsim_id_list_lo[50:150]\n",
    "\n",
    "# define folder with discharge timeseries data\n",
    "fol_in = f'{data_dir}/GSIM_data/GSIM_indices/TIMESERIES/yearly/'\n",
    "\n",
    "# define output folder\n",
    "fol_out = f'{out_dir}/gsim/'\n",
    "\n",
    "# make lists for parallel computation\n",
    "catch_list = gsim_id_list_lo\n",
    "fol_in_list = [fol_in] * len(catch_list)\n",
    "fol_out_list = [fol_out] * len(catch_list)\n",
    "\n",
    "# run function\n",
    "run_function_parallel(catch_list,fol_in_list,fol_out_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aacae4-7dfe-4ed1-9c51-0838801bdf7d",
   "metadata": {},
   "source": [
    "### 2.3 select GSIM catchments\n",
    "Here we select GSIM catchments that are used for further analysis. The selection criteria are as follows:\n",
    " - timeseries after 1980 contains at least 10 years of data\n",
    " - area quality high or medium\n",
    "\n",
    "If a year has less than 250 days with data, the year is set to nan, and we remove nan years from the timeseries.\n",
    "It is ok to have non-consecutive years in our timeseries.\n",
    "\n",
    "The function *select_catchments* in *f_preprocess_discharge.py* selects catchments and stores the selected timeseries in a separate folder.\n",
    "Here we do a test run with only 5 catchments to reduce computational time. Run all catchments on Delftblue using slurm and the *run_gsim_selection.py* script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77e7bc56-f1c7-4e69-b231-4cf94dbb0fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load catchment ids\n",
    "gsim_id_list_lo = np.loadtxt(f'{out_dir}/gsim/gsim_catch_id_list_lo.txt',dtype=str) \n",
    "\n",
    "# select randomly 5 catchments\n",
    "# gsim_id_list_lo = random.choices(gsim_id_list_lo,k=5)\n",
    "gsim_id_list_lo = gsim_id_list_lo[50:150]\n",
    "\n",
    "# make lists for parallel computation\n",
    "catch_list = gsim_id_list_lo\n",
    "data_dir_list = [data_dir] * len(catch_list)\n",
    "out_dir_list = [out_dir] * len(catch_list)\n",
    "\n",
    "# run function\n",
    "run_function2_parallel(data_dir_list,out_dir_list,catch_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd80a39-6bb2-4da1-b17d-33834b8b7080",
   "metadata": {},
   "source": [
    "Make here lists of the selected catchment ids, that are stored in the previous step in the *timeseries_selected* folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e29d5cdf-ac32-4225-bb40-b2198198e1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsim_id_list_up_sel = []\n",
    "gsim_id_list_lo_sel = []\n",
    "for filepath in glob.iglob(f'{out_dir}/gsim/timeseries_selected/*'):\n",
    "    f = os.path.split(filepath)[1] # remove full path\n",
    "    f = f[:-4] # remove .csv extension\n",
    "    fl = f.lower()\n",
    "    gsim_id_list_up_sel.append(f)\n",
    "    gsim_id_list_lo_sel.append(fl)\n",
    "    \n",
    "np.savetxt(f'{out_dir}/gsim/gsim_catch_id_list_up_sel.txt',gsim_id_list_up_sel,fmt='%s')\n",
    "np.savetxt(f'{out_dir}/gsim/gsim_catch_id_list_lo_sel.txt',gsim_id_list_lo_sel,fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea90e0c0",
   "metadata": {},
   "source": [
    "### 3. Organize data\n",
    "\n",
    "**Add Australia CAMELS catchments**\\\n",
    "The CAMELS-AU data is added to GSIM to get a better representation of climate regions. The discharge data is stored in /data/CAMELS_AUS/ and is processed using *preprocess_q_aus.py*\n",
    "Output is stored in /output/camels-aus/\n",
    "\n",
    "Here we assume all catchments are ok for Australia. \n",
    "- Copy all files in /output/camels_aus/ to /output/gsim/timeseries_selected/ (do manually) folder to complete the GSIM dataset, and move one folder up in output/\n",
    "- And we need to make a new list with selected catchments including australia - see below.\n",
    "- Copy all shapefiles of the selected GSIM and CAMELS-AUS catchments into /output/selected_shapes/\n",
    "- Copy all selected q_timeseries in /output/gsim/timeseries_selected to /output/q_timeseries_selected/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4efa4b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsim_id_aus_list_up_sel = []\n",
    "gsim_id_aus_list_lo_sel = []\n",
    "for filepath in glob.iglob(f'{out_dir}/q_timeseries_selected/*'):\n",
    "    f = os.path.split(filepath)[1] # remove full path\n",
    "    f = f[:-4] # remove .csv extension\n",
    "    fl = f.lower()\n",
    "    gsim_id_aus_list_up_sel.append(f)\n",
    "    gsim_id_aus_list_lo_sel.append(f)\n",
    "    \n",
    "np.savetxt(f'{out_dir}/gsim_aus_catch_id_list_up_sel.txt',gsim_id_aus_list_up_sel,fmt='%s')\n",
    "np.savetxt(f'{out_dir}/gsim_aus_catch_id_list_lo_sel.txt',gsim_id_aus_list_lo_sel,fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2f4f037a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['102101A' 'ar_0000001' 'ar_0000005' ... 'G9030124' 'G9030250' 'G9070142']\n",
      "The amount of selected catchments is: 8658\n"
     ]
    }
   ],
   "source": [
    "catch_list = np.loadtxt(f'{out_dir}/gsim_aus_catch_id_list_up_sel.txt',dtype=str)\n",
    "print(catch_list)\n",
    "print('The amount of selected catchments is:',len(catch_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfb49e0-e014-45eb-ac49-200b78d4c9b5",
   "metadata": {},
   "source": [
    "### 5. From gridded data to catchment timeseries\n",
    "For this step go to the notebook *run_script_grid_to_catchments*. This part is run in another notebook. The output data of this script can be found in:\n",
    "- */output/p_gswp_timeseries_selected_catchments*\n",
    "- */output/ep_gswp_timeseries_selected_catchments*\n",
    "- */output/tas_gswp_timeseries_selected_catchments*\n",
    "\n",
    "all daily output timeseries are collected together in */output/forcing_timeseries/raw/*\n",
    "\n",
    "Below we postprocess the daily outputs in this folder using the *process_forcing_timeseries* that was defined in *f_grid_to_catchments.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41b643a5-9e5c-4ea9-92c6-f4bffc2c842c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102101A\n",
      "ar_0000001\n",
      "ar_0000005\n",
      "ar_0000006\n",
      "ar_0000008\n"
     ]
    }
   ],
   "source": [
    "# define input directory\n",
    "fol_in=f'{work_dir}/output/forcing_timeseries/raw'\n",
    "# define output directory\n",
    "fol_out=f'{work_dir}/output/forcing_timeseries/processed'\n",
    "\n",
    "# get catch_id_list\n",
    "catch_id_list = np.genfromtxt(f'{work_dir}/output/gsim_aus_catch_id_list_up_sel.txt',dtype='str')\n",
    "\n",
    "# define variables\n",
    "# var = ['Ep','P','T']\n",
    "var = ['ep','p','tas']\n",
    "\n",
    "# run process_forcing_timeseries (defined in f_grid_to_catchments.py) for all catchments in catch_id_list\n",
    "for catch_id in catch_id_list[0:5]:\n",
    "    print(catch_id)\n",
    "    process_forcing_timeseries(catch_id,fol_in,fol_out,var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "058894a0-089b-484a-b236-fa5c75ffa998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in parallel\n",
    "# make lists for parallel computation\n",
    "catch_list = catch_id_list[0:5]\n",
    "fol_in_list = [fol_in] * len(catch_list)\n",
    "fol_out_list = [fol_out] * len(catch_list)\n",
    "var_list = [var] * len(catch_list)\n",
    "run_function_parallel(catch_list,fol_in_list,fol_out_list,var_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7db8dd-39f3-4b02-93fc-2faaf74cb75b",
   "metadata": {},
   "source": [
    "### 6. Google earth engine for catchment characteristics\n",
    "For this step go to the notebook *run_script_earthengine*. This part is run in another notebook. The output data of this script can be found in *work_dir/output/earth_engine_timeseries*.\\\\\n",
    "\n",
    "- Treecover output is stored in */output/treecover/gsim_shapes_treecover.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02bcf811-7627-47d2-a0ea-95b4ea322f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(f'{work_dir}/output/treecover/gsim_shapes_treecover.csv')# this includes ausdata!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36fb8244-847f-49c2-8e15-788c64603eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catch_id</th>\n",
       "      <th>max_tc</th>\n",
       "      <th>mean_tc</th>\n",
       "      <th>min_tc</th>\n",
       "      <th>std_tc</th>\n",
       "      <th>max_ntc</th>\n",
       "      <th>mean_ntc</th>\n",
       "      <th>min_ntc</th>\n",
       "      <th>std_ntc</th>\n",
       "      <th>mean_nonveg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>es_0000991</td>\n",
       "      <td>15.243561</td>\n",
       "      <td>13.808580</td>\n",
       "      <td>12.493691</td>\n",
       "      <td>0.636526</td>\n",
       "      <td>57.197720</td>\n",
       "      <td>56.313709</td>\n",
       "      <td>55.520272</td>\n",
       "      <td>0.392144</td>\n",
       "      <td>29.877711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us_0003601</td>\n",
       "      <td>14.275355</td>\n",
       "      <td>9.511785</td>\n",
       "      <td>6.392207</td>\n",
       "      <td>1.721643</td>\n",
       "      <td>67.860510</td>\n",
       "      <td>65.816688</td>\n",
       "      <td>62.263939</td>\n",
       "      <td>1.119623</td>\n",
       "      <td>24.671527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>at_0000053</td>\n",
       "      <td>50.507838</td>\n",
       "      <td>50.102189</td>\n",
       "      <td>49.626189</td>\n",
       "      <td>0.215605</td>\n",
       "      <td>34.260899</td>\n",
       "      <td>33.568141</td>\n",
       "      <td>33.006469</td>\n",
       "      <td>0.299617</td>\n",
       "      <td>16.329669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>br_0000155</td>\n",
       "      <td>77.748960</td>\n",
       "      <td>58.329329</td>\n",
       "      <td>8.940161</td>\n",
       "      <td>15.100569</td>\n",
       "      <td>64.931697</td>\n",
       "      <td>32.660881</td>\n",
       "      <td>15.749590</td>\n",
       "      <td>10.190070</td>\n",
       "      <td>9.009789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>br_0000270</td>\n",
       "      <td>57.168027</td>\n",
       "      <td>52.837786</td>\n",
       "      <td>49.642269</td>\n",
       "      <td>1.824748</td>\n",
       "      <td>30.296366</td>\n",
       "      <td>28.051420</td>\n",
       "      <td>25.201100</td>\n",
       "      <td>1.248870</td>\n",
       "      <td>19.110795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8653</th>\n",
       "      <td>ca_0000685</td>\n",
       "      <td>22.964986</td>\n",
       "      <td>21.533746</td>\n",
       "      <td>20.533114</td>\n",
       "      <td>0.622028</td>\n",
       "      <td>57.624616</td>\n",
       "      <td>56.890292</td>\n",
       "      <td>55.757891</td>\n",
       "      <td>0.479737</td>\n",
       "      <td>21.575962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8654</th>\n",
       "      <td>br_0001618</td>\n",
       "      <td>29.386886</td>\n",
       "      <td>27.847346</td>\n",
       "      <td>25.567657</td>\n",
       "      <td>0.968407</td>\n",
       "      <td>67.103698</td>\n",
       "      <td>65.545956</td>\n",
       "      <td>64.460628</td>\n",
       "      <td>0.671841</td>\n",
       "      <td>6.606699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8655</th>\n",
       "      <td>ca_0003506</td>\n",
       "      <td>52.700973</td>\n",
       "      <td>39.405013</td>\n",
       "      <td>12.713426</td>\n",
       "      <td>8.301865</td>\n",
       "      <td>67.163324</td>\n",
       "      <td>44.873497</td>\n",
       "      <td>29.063317</td>\n",
       "      <td>8.865259</td>\n",
       "      <td>15.721489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8656</th>\n",
       "      <td>ca_0000056</td>\n",
       "      <td>55.742350</td>\n",
       "      <td>54.968785</td>\n",
       "      <td>52.830302</td>\n",
       "      <td>0.693286</td>\n",
       "      <td>33.468020</td>\n",
       "      <td>31.661629</td>\n",
       "      <td>30.733066</td>\n",
       "      <td>0.598757</td>\n",
       "      <td>13.369586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8657</th>\n",
       "      <td>ca_0000003</td>\n",
       "      <td>56.414286</td>\n",
       "      <td>53.825957</td>\n",
       "      <td>52.260580</td>\n",
       "      <td>0.678506</td>\n",
       "      <td>39.021480</td>\n",
       "      <td>36.570240</td>\n",
       "      <td>33.831432</td>\n",
       "      <td>0.974125</td>\n",
       "      <td>9.603803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8658 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        catch_id     max_tc    mean_tc     min_tc     std_tc    max_ntc  \\\n",
       "0     es_0000991  15.243561  13.808580  12.493691   0.636526  57.197720   \n",
       "1     us_0003601  14.275355   9.511785   6.392207   1.721643  67.860510   \n",
       "2     at_0000053  50.507838  50.102189  49.626189   0.215605  34.260899   \n",
       "3     br_0000155  77.748960  58.329329   8.940161  15.100569  64.931697   \n",
       "4     br_0000270  57.168027  52.837786  49.642269   1.824748  30.296366   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "8653  ca_0000685  22.964986  21.533746  20.533114   0.622028  57.624616   \n",
       "8654  br_0001618  29.386886  27.847346  25.567657   0.968407  67.103698   \n",
       "8655  ca_0003506  52.700973  39.405013  12.713426   8.301865  67.163324   \n",
       "8656  ca_0000056  55.742350  54.968785  52.830302   0.693286  33.468020   \n",
       "8657  ca_0000003  56.414286  53.825957  52.260580   0.678506  39.021480   \n",
       "\n",
       "       mean_ntc    min_ntc    std_ntc  mean_nonveg  \n",
       "0     56.313709  55.520272   0.392144    29.877711  \n",
       "1     65.816688  62.263939   1.119623    24.671527  \n",
       "2     33.568141  33.006469   0.299617    16.329669  \n",
       "3     32.660881  15.749590  10.190070     9.009789  \n",
       "4     28.051420  25.201100   1.248870    19.110795  \n",
       "...         ...        ...        ...          ...  \n",
       "8653  56.890292  55.757891   0.479737    21.575962  \n",
       "8654  65.545956  64.460628   0.671841     6.606699  \n",
       "8655  44.873497  29.063317   8.865259    15.721489  \n",
       "8656  31.661629  30.733066   0.598757    13.369586  \n",
       "8657  36.570240  33.831432   0.974125     9.603803  \n",
       "\n",
       "[8658 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecbdbeb-4659-482d-802d-dccd600b1658",
   "metadata": {},
   "source": [
    "### 7. Catchment descriptor variables\n",
    "For the global root zone storage capacity estimation, we need to calculate catchment descriptor variables. These descriptors can be climatological variables (e.g. mean precipitation (p_mean); seasonality of precipitation (si_p); timelag between maximum P and Ep (phi)) or landscape variables (e.g. mean treecover (tc); mean elevation (h_mean)). A detailed list of all the descriptors considered is provided here xxxxx.\\\n",
    "To calculate the catchment descriptor variables we use the *catch_characteristics* function from the *f_catch_characteristics.py* file. In this function you specify the variables of interest, the catchment ID and your in- and output folders. Then, based on all the timeseries you have generated in the preceding codes it will return a table with the catchment descriptor variables for all your catchments (that is saved as csv in your *work_dir/catchment_characteristics.csv*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ab7412-ed47-47a1-b5be-cff509d48929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# define in and output folder\n",
    "fol_in=f'{work_dir}/output/'\n",
    "fol_out=f'{work_dir}/output/'\n",
    "\n",
    "# define variables of interest\n",
    "var=['p_mean','ep_mean','q_mean','t_mean','ai','si_p','si_ep','phi','tc','ntc','nonveg','area']\n",
    "\n",
    "catch_id_list = np.genfromtxt(f'{work_dir}/output/gsim_aus_catch_id_list_lo_sel.txt',dtype='str')[0:3] # test for 3 catchments -> run on delftblue for all catchments with catch_characteristics.py\n",
    "\n",
    "# make lists for parallel computation\n",
    "catch_list = catch_id_list.tolist()\n",
    "var_list = [var] * len(catch_list)\n",
    "fol_in_list = [fol_in] * len(catch_list)\n",
    "fol_out_list = [fol_out] * len(catch_list)\n",
    "\n",
    "# run catch_characteristics (defined in f_catch_characteristics.py) for the catchments in your catch_id_list parallel\n",
    "run_function_parallel_catch_characteristics(var_list,catch_list,fol_in_list,fol_out_list)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4834ec33-ab49-4c44-82f6-1227b18813dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all files in one dataframe\n",
    "# list al shapefiles    \n",
    "files = glob.glob(f\"{work_dir}/output/catchment_characteristics/*\")\n",
    "li=[] #empty list\n",
    "for filename in files:\n",
    "    df = pd.read_csv(filename, index_col=0) #read file as dataframe\n",
    "    li.append(df) #append file to list\n",
    "f = pd.concat(li, axis=0) #concatenate lists\n",
    "f.to_csv(f'{out_dir}/catchment_characteristics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8cf3227-0d86-4ff5-ad30-d862fb8d2e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_mean</th>\n",
       "      <th>ep_mean</th>\n",
       "      <th>q_mean</th>\n",
       "      <th>t_mean</th>\n",
       "      <th>ai</th>\n",
       "      <th>si_p</th>\n",
       "      <th>si_ep</th>\n",
       "      <th>phi</th>\n",
       "      <th>tc</th>\n",
       "      <th>ntc</th>\n",
       "      <th>nonveg</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102101A</th>\n",
       "      <td>26.111414</td>\n",
       "      <td>5.013324</td>\n",
       "      <td>2.451285</td>\n",
       "      <td>3.821485</td>\n",
       "      <td>5.208403</td>\n",
       "      <td>0.052301</td>\n",
       "      <td>0.845662</td>\n",
       "      <td>1</td>\n",
       "      <td>23.077881</td>\n",
       "      <td>64.030838</td>\n",
       "      <td>12.891281</td>\n",
       "      <td>6.484000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ar_0000008</th>\n",
       "      <td>21.514082</td>\n",
       "      <td>4.478494</td>\n",
       "      <td>1.094832</td>\n",
       "      <td>2.804694</td>\n",
       "      <td>4.803865</td>\n",
       "      <td>0.166373</td>\n",
       "      <td>0.279538</td>\n",
       "      <td>3</td>\n",
       "      <td>17.329813</td>\n",
       "      <td>70.978290</td>\n",
       "      <td>11.691898</td>\n",
       "      <td>1.510756e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ar_0000001</th>\n",
       "      <td>2.870530</td>\n",
       "      <td>22.567559</td>\n",
       "      <td>1.354127</td>\n",
       "      <td>4.287819</td>\n",
       "      <td>0.127197</td>\n",
       "      <td>0.213515</td>\n",
       "      <td>0.083267</td>\n",
       "      <td>1</td>\n",
       "      <td>19.960333</td>\n",
       "      <td>68.424506</td>\n",
       "      <td>11.615161</td>\n",
       "      <td>8.918319e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ar_0000005</th>\n",
       "      <td>23.028048</td>\n",
       "      <td>2.942214</td>\n",
       "      <td>0.864945</td>\n",
       "      <td>3.631584</td>\n",
       "      <td>7.826776</td>\n",
       "      <td>0.095058</td>\n",
       "      <td>0.232785</td>\n",
       "      <td>0</td>\n",
       "      <td>23.192699</td>\n",
       "      <td>64.258747</td>\n",
       "      <td>12.548554</td>\n",
       "      <td>2.021051e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ar_0000006</th>\n",
       "      <td>2.883051</td>\n",
       "      <td>22.474773</td>\n",
       "      <td>0.669215</td>\n",
       "      <td>3.527318</td>\n",
       "      <td>0.128279</td>\n",
       "      <td>0.251582</td>\n",
       "      <td>0.108883</td>\n",
       "      <td>0</td>\n",
       "      <td>21.858087</td>\n",
       "      <td>65.052455</td>\n",
       "      <td>13.089458</td>\n",
       "      <td>2.298484e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zw_0000041</th>\n",
       "      <td>3.142379</td>\n",
       "      <td>18.777279</td>\n",
       "      <td>0.360042</td>\n",
       "      <td>2.897911</td>\n",
       "      <td>0.167350</td>\n",
       "      <td>0.224099</td>\n",
       "      <td>0.108324</td>\n",
       "      <td>0</td>\n",
       "      <td>16.590410</td>\n",
       "      <td>64.299494</td>\n",
       "      <td>19.110096</td>\n",
       "      <td>1.257873e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zw_0000065</th>\n",
       "      <td>2.725506</td>\n",
       "      <td>2.116412</td>\n",
       "      <td>0.313023</td>\n",
       "      <td>18.894012</td>\n",
       "      <td>1.287796</td>\n",
       "      <td>0.201911</td>\n",
       "      <td>0.901798</td>\n",
       "      <td>0</td>\n",
       "      <td>13.106703</td>\n",
       "      <td>68.745179</td>\n",
       "      <td>18.148118</td>\n",
       "      <td>3.315826e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zw_0000068</th>\n",
       "      <td>3.138246</td>\n",
       "      <td>2.838255</td>\n",
       "      <td>0.464055</td>\n",
       "      <td>19.060713</td>\n",
       "      <td>1.105695</td>\n",
       "      <td>0.827212</td>\n",
       "      <td>0.205115</td>\n",
       "      <td>0</td>\n",
       "      <td>18.563534</td>\n",
       "      <td>65.035161</td>\n",
       "      <td>16.401305</td>\n",
       "      <td>2.223119e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zw_0000077</th>\n",
       "      <td>1.735157</td>\n",
       "      <td>2.733249</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>19.664812</td>\n",
       "      <td>0.634833</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.218184</td>\n",
       "      <td>1</td>\n",
       "      <td>7.357007</td>\n",
       "      <td>72.066081</td>\n",
       "      <td>20.576912</td>\n",
       "      <td>3.939916e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zw_0000082</th>\n",
       "      <td>2.624977</td>\n",
       "      <td>1.596364</td>\n",
       "      <td>0.141135</td>\n",
       "      <td>20.454506</td>\n",
       "      <td>1.644347</td>\n",
       "      <td>0.232462</td>\n",
       "      <td>0.880452</td>\n",
       "      <td>0</td>\n",
       "      <td>6.238818</td>\n",
       "      <td>70.530620</td>\n",
       "      <td>23.230562</td>\n",
       "      <td>2.593699e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8658 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               p_mean    ep_mean    q_mean     t_mean        ai      si_p  \\\n",
       "102101A     26.111414   5.013324  2.451285   3.821485  5.208403  0.052301   \n",
       "ar_0000008  21.514082   4.478494  1.094832   2.804694  4.803865  0.166373   \n",
       "ar_0000001   2.870530  22.567559  1.354127   4.287819  0.127197  0.213515   \n",
       "ar_0000005  23.028048   2.942214  0.864945   3.631584  7.826776  0.095058   \n",
       "ar_0000006   2.883051  22.474773  0.669215   3.527318  0.128279  0.251582   \n",
       "...               ...        ...       ...        ...       ...       ...   \n",
       "zw_0000041   3.142379  18.777279  0.360042   2.897911  0.167350  0.224099   \n",
       "zw_0000065   2.725506   2.116412  0.313023  18.894012  1.287796  0.201911   \n",
       "zw_0000068   3.138246   2.838255  0.464055  19.060713  1.105695  0.827212   \n",
       "zw_0000077   1.735157   2.733249  0.030142  19.664812  0.634833  0.905109   \n",
       "zw_0000082   2.624977   1.596364  0.141135  20.454506  1.644347  0.232462   \n",
       "\n",
       "               si_ep  phi         tc        ntc     nonveg          area  \n",
       "102101A     0.845662    1  23.077881  64.030838  12.891281  6.484000e+02  \n",
       "ar_0000008  0.279538    3  17.329813  70.978290  11.691898  1.510756e+04  \n",
       "ar_0000001  0.083267    1  19.960333  68.424506  11.615161  8.918319e+05  \n",
       "ar_0000005  0.232785    0  23.192699  64.258747  12.548554  2.021051e+06  \n",
       "ar_0000006  0.108883    0  21.858087  65.052455  13.089458  2.298484e+06  \n",
       "...              ...  ...        ...        ...        ...           ...  \n",
       "zw_0000041  0.108324    0  16.590410  64.299494  19.110096  1.257873e+02  \n",
       "zw_0000065  0.901798    0  13.106703  68.745179  18.148118  3.315826e+03  \n",
       "zw_0000068  0.205115    0  18.563534  65.035161  16.401305  2.223119e+03  \n",
       "zw_0000077  0.218184    1   7.357007  72.066081  20.576912  3.939916e+02  \n",
       "zw_0000082  0.880452    0   6.238818  70.530620  23.230562  2.593699e+02  \n",
       "\n",
       "[8658 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c08a8c1d-1841-402a-8139-1f702fefde12",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1619/3108765287.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mli\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#empty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshapefiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#read shapefile as geopandas dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#append shapefile to list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#concatenate lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sr_env/lib/python3.9/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfiona_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;31m# In a future Fiona release the crs attribute of features will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sr_env/lib/python3.9/site-packages/fiona/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sr_env/lib/python3.9/site-packages/fiona/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[0m\u001b[1;32m    257\u001b[0m                            layer=layer, enabled_drivers=enabled_drivers, **kwargs)\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sr_env/lib/python3.9/site-packages/fiona/collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shapefiles = glob.glob(f\"{work_dir}/output/selected_shapes/*shp\")[:]\n",
    "li=[] #empty list\n",
    "for filename in shapefiles:\n",
    "    df = gpd.read_file(filename, index_col=None, header=0) #read shapefile as geopandas dataframe\n",
    "    li.append(df) #append shapefile to list\n",
    "f = pd.concat(li, axis=0) #concatenate lists\n",
    "f = f.rename(columns={'FILENAME':'catch_id'})\n",
    "f.index = f['catch_id']\n",
    "f = f.drop(columns={'catch_id','Id'})\n",
    "f.to_file(f'{out_dir}/geo_catchments.shp') #store geopandas dataframe as .shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd0acc4-36d3-4d3e-a304-875554e822dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95319679-461d-4b75-aca0-bbf9cfbf692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine catchment geometries in single shapefile\n",
    "shape_dir = f'{data_dir}/shapes/'\n",
    "out_dir = f'{work_dir}/output'\n",
    "geo_catchments(shape_dir,out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f2a634-2971-4984-9de2-993faad4ac48",
   "metadata": {},
   "source": [
    "## check also for WB and for AREA (<10000km2) - see catchment_waterbalance.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f9e214-04ed-499e-9e45-845bc7d74c23",
   "metadata": {},
   "source": [
    "### 8. Calculate root zone storage capacity\n",
    "Here we calculate the catchment root zone storage capacity (Sr) based on catchment water balances. First, catchment root zone storage deficits (Sd) are computed as the cumulative difference between P and Et (transpiration). The result of one catchment is visualised in a figure. Second, the Sr is then calculated based on an extreme value analysis of the storage deficits for different return periods. A detailed description of this method can be found here xxxxxx.\n",
    "\n",
    "Here we use the *run_sd_calculation* and *run_sr_calculation* functions from the *f_sr_calculation* file. The Sd result of one catchment is visualised using *plot_sd*. The Sr results are merged using the *merge_sr* function and visualised using the *plot_sr* function. The output of both storage deficit and Sr calculations are saved in your *work_dir/output/sr_calculation*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409d935d-0bc8-473f-9018-a12a7af16576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output directories\n",
    "if not os.path.exists(f'{work_dir}/output/sr_calculation/sd_catchments'):\n",
    "    os.makedirs(f'{work_dir}/output/sr_calculation/sd_catchments')\n",
    "    \n",
    "if not os.path.exists(f'{work_dir}/output/sr_calculation/sr_catchments'):\n",
    "    os.makedirs(f'{work_dir}/output/sr_calculation/sr_catchments')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4bed7a-fd38-422a-9577-e20cf6be7bac",
   "metadata": {},
   "source": [
    "Calculate storage deficits using the *run_sd_calculation* function from *f_sr_calculation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0641804-4e6a-4a1c-ad7d-fceaec17bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories\n",
    "pep_dir = f'{work_dir}/output/forcing_timeseries/processed/daily'\n",
    "q_dir = f'{work_dir}/output/discharge/timeseries'\n",
    "out_dir = f'{work_dir}/output/sr_calculation/sd_catchments'\n",
    "\n",
    "# run sd calculation for all catchments in catch_id_list\n",
    "for catch_id in catch_id_list:\n",
    "    run_sd_calculation(catch_id, pep_dir, q_dir, out_dir)\n",
    "    \n",
    "#comRuud: print to screen what is being created (for some reason I did not get an Sd for the US catchment, but no error!)\n",
    "# Fransje: this is correct, incorrect water balance in us catchment -> no sd calculated. add flag or so in table??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84c3b66-6d7e-4081-bfb1-6cec197d70db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sd example - use the first catchment from catch_id_list\n",
    "sd_dir = f'{work_dir}/output/sr_calculation/sd_catchments'\n",
    "plot_sd(catch_id_list[0], sd_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893710c3-63f6-482d-b348-9a434e79e787",
   "metadata": {},
   "source": [
    "Calculate Sr using the *run_sr_calculation* function from *f_sr_calculation* and merge the catchment Sr values into one dataframe with *merge_sr_catchments*. The functions return a table with the catchment Sr values for the different return periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882c1d56-675c-49a4-89e0-b1c5b40054c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories\n",
    "sd_dir = f'{work_dir}/output/sr_calculation/sd_catchments'\n",
    "out_dir = f'{work_dir}/output/sr_calculation/sr_catchments'\n",
    "\n",
    "# define return periods\n",
    "rp_array = [2,3,5,10,20,30,40,50,60]\n",
    "\n",
    "# run sr calculation for all catchments in catch_id_list\n",
    "for catch_id in catch_id_list:\n",
    "    run_sr_calculation(catch_id, rp_array, sd_dir, out_dir)\n",
    "    \n",
    "# merge catchment sr dataframes into one dataframe\n",
    "sr_dir = f'{work_dir}/output/sr_calculation/sr_catchments'\n",
    "out_dir = f'{work_dir}/output/sr_calculation/'\n",
    "merge_sr_catchments(sr_dir,out_dir)\n",
    "\n",
    "#comRuud: multiple Sr have been created (for different return periods? But values are the same, is that correct?) print to screen and tell what it should look like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce395fd-fe07-444f-942c-6d2cae88823e",
   "metadata": {},
   "source": [
    "Mapping Sr using the *plot_sr* function from *f_sr_calculation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c841ffa-b51a-4e41-b34b-015b0c14572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_file = f'{work_dir}/output/sr_calculation/sr_all_catchments.csv'\n",
    "shp_file = f'{work_dir}/output/geo_catchments.shp'\n",
    "rp=20\n",
    "plot_sr(shp_file,sr_file,rp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ed214-c93f-40bd-bf5e-7e215dfc8066",
   "metadata": {},
   "source": [
    "### 9. Regression\n",
    "\n",
    "**move this to different script? to separate 'preprocessing' and 'analysis'?**\n",
    "\n",
    "Here we run the linear regression model to predict the catchment Sr values based on the descriptor parameters. We use the *f_regression* function to calculate the linear regression parameters for the considered catchments.\n",
    "We use the treecover data to separate the regression for high and low vegetation, the threshold values for tree cover (tc), non tree cover (ntc) and no-vegetation (nonveg) define this separation.\n",
    "\n",
    "The output is a figure showing the estimated (step 8) and predicted (from regression) Sr values and a table with the regression parameter values, some statistics for the regression performance and the threshold values for tree cover. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549b3ebf-5db9-4eda-9832-2439c8d960c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the catchment characteristics and sr tables\n",
    "cc_df = pd.read_csv(f'{work_dir}/output/catchment_characteristics.csv',index_col=0)\n",
    "sr_df = pd.read_csv(f'{work_dir}/output/sr_calculation/sr_all_catchments.csv',index_col=0)\n",
    "\n",
    "# define the descriptor variables\n",
    "dpar = ['p_mean','ep_mean','t_mean','si_p']\n",
    "\n",
    "# return period of Sr estimate\n",
    "rp = 20\n",
    "\n",
    "# define the vegetation thresholds for the regression\n",
    "tc_th, ntc_th, nonveg_th = 10, 0, 0\n",
    "\n",
    "# run the regression (r_regression in f_regression.py)\n",
    "run_regression(cc_df, sr_df, dpar, rp, tc_th, ntc_th, nonveg_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3784f57-4033-469b-9191-7296fd3d89dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
