{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62e3f38f-c900-4727-a9e1-2735ae539100",
   "metadata": {},
   "source": [
    "# Run script - gridded data to catchment timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ac8f8-f3cb-4841-a27f-c6ce951f46b9",
   "metadata": {},
   "source": [
    "In this script we extract catchment timeseries of precipitation, potential evaporation and temperature from global gridded products. \n",
    "\n",
    "This scripts only works in the conda environment **sr_env**. In this environment all required packages are available. If you have **not** installed and activated this environment before opening this script, you should check the installation section in the *README* file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f072c26-9428-4158-b011-45a7bf495721",
   "metadata": {},
   "source": [
    "### 1. Getting started\n",
    "First, import all the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12476d9c-f4d9-41d7-889e-4e84ec7ee35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import iris\n",
    "import iris.pandas\n",
    "import numpy as np\n",
    "from esmvalcore import preprocessor\n",
    "from iris.coords import DimCoord\n",
    "from iris.cube import Cube\n",
    "from pathos.threading import ThreadPool as Pool\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d94080-a55a-49dc-bfd7-09ef86d1ffa2",
   "metadata": {},
   "source": [
    "Here we import all the python functions defined in the scripts *f_grid_to_catchments.py*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b053a7a-23b8-434d-ae1d-19888e5f5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python functions\n",
    "from f_grid_to_catchments import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a9ed88-646a-4209-b0a1-5e01426119ee",
   "metadata": {},
   "source": [
    "### 2. Define working and data directories\n",
    "Here we define the working directory, where all the scripts and output are saved.\n",
    "\n",
    "We also definet he data directory where you have the following subdirectories:\n",
    "\n",
    "/data/forcing/*netcdf forcing files*\\\n",
    "/data/shapes/*catchment shapefiles*\\\n",
    "/data/gsim_discharge/*gsim discharge timeseries*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f877d246-f504-49af-b482-f01a249ecc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fransjevanoors/global_sr_module'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check current working directory (helpful when filling in work_dir below)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48e094df-ec04-4c83-a259-9a4395300ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your script working directory\n",
    "# work_dir=Path(\"/home/fransjevanoors/global_sr_module\")\n",
    "# work_dir=Path(\"/work/users/vanoorschot/fransje/scripts/GLOBAL_SR/global_sr_module\")\n",
    "# define your data directory\n",
    "# data_dir=Path(\"/work/users/vanoorschot/fransje/scripts/GLOBAL_SR/global_sr_module/data\")\n",
    "work_dir=Path(\"/scratch/fransjevanoors/global_sr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfb49e0-e014-45eb-ac49-200b78d4c9b5",
   "metadata": {},
   "source": [
    "### 3. From gridded data to catchment timeseries\n",
    "We don't have data on precipitation, potential evaporation and temperature at the catchment scale. Therefore, we use global gridded products of these parameters (there are a lot of possibilities which data to use). For doing analyses at the catchment scale, we need to convert these gridded products into catchment timeseries.\n",
    "To do this, we calculate the mean parameter values of the gridcells that fall within the catchment shapes. The procedure is defined by the functions in the *f_grid_to_catchments.py* file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a121ca04-36e3-45c4-a687-0de3848a696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output directories\n",
    "if not os.path.exists(f'{work_dir}/output/forcing_timeseries/raw'):\n",
    "    os.makedirs(f'{work_dir}/output/forcing_timeseries/raw')\n",
    "if not os.path.exists(f'{work_dir}/output/forcing_timeseries/processed'):\n",
    "    os.makedirs(f'{work_dir}/output/forcing_timeseries/processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "effae491-88d1-4129-9c96-be010c08048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories \n",
    "SHAPE_DIR = Path(f'{data_dir}/shapes/') # dir of shapefiles\n",
    "NC4_DIR = Path(f'{data_dir}/forcing/') # dir of netcdf forcing files\n",
    "OUT_DIR = Path(f'{work_dir}/output/forcing_timeseries/raw') # output dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25df1f20-ffb8-4977-a5d3-eb8f6823f620",
   "metadata": {},
   "source": [
    "The conversion from grid to catchment is computationally expensive. Therefore, we run this conversion for all catchments in parallel using the python function *pathos threadpool* (https://pathos.readthedocs.io/en/latest/pathos.html#module-pathos.threading).\n",
    "With the *construct_lists_for_parallel_function* function from *f_grid_to_catchments.py* we create lists that contain all combinations of shapefile, netcdf-file and output-directory. OPERATOR LIST NOT NEEDED?. These lists are the input for the *run_function_parallel* function from *f_grid_to_catchments.py*, which returns timeseries of the catchment mean values of precipitation (P), potential evaporation (Ep) and  temperature (T). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "231a7885-48c3-47c2-af34-5d3e682a8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct lists for parallel run\n",
    "(shapefile_list, netcdf_list, operator_list, output_dir_list) = construct_lists_for_parallel_function(NC4_DIR, SHAPE_DIR, OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e28d5df1-69e7-4bb1-ac8a-ced200967d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run function parallel\n",
    "run_function_parallel(shapefile_list, netcdf_list, operator_list, output_dir_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec7d309-611d-4df3-ad73-778db1361987",
   "metadata": {},
   "source": [
    "The output of the *run_function_parallel* function contains daily timeseries of P, Ep and T for all catchments. Here we postprocess these data to get dataframes containing Ep, P and T together with daily, monthly and yearly timeseries, climatology and mean values (stored as *csv* files). This postprocessing is done in the *process_forcing_timeseries* function defined in *f_grid_to_catchments.py*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e2bc092-97f9-4cec-bd0f-97aba6990b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input directory\n",
    "fol_in=f'{work_dir}/output/forcing_timeseries/raw'\n",
    "# define output directory\n",
    "fol_out=f'{work_dir}/output/forcing_timeseries/processed'\n",
    "\n",
    "# get catch_id_list\n",
    "catch_id_list = np.genfromtxt(f'{work_dir}/output/catch_id_list.txt',dtype='str')\n",
    "\n",
    "# define variables\n",
    "var = ['Ep','P','T']\n",
    "\n",
    "# run process_forcing_timeseries (defined in f_grid_to_catchments.py) for all catchments in catch_id_list\n",
    "for catch_id in catch_id_list:\n",
    "    process_forcing_timeseries(catch_id,fol_in,fol_out,var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd544713-b9cc-41fa-93ed-3279f16f6079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/work/users/vanoorschot/fransje/scripts/GLOBAL_SR/global_sr_module/output/forcing_timeseries/processed/daily/br_0000495_1995_2000.csv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ep</th>\n",
       "      <th>P</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995-01-01</th>\n",
       "      <td>3.011033</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>28.862823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-02</th>\n",
       "      <td>3.397685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.742493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-03</th>\n",
       "      <td>3.092484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.230500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-04</th>\n",
       "      <td>3.917221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.689178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-05</th>\n",
       "      <td>4.295576</td>\n",
       "      <td>0.019365</td>\n",
       "      <td>28.674103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Ep         P          T\n",
       "time                                     \n",
       "1995-01-01  3.011033  0.004925  28.862823\n",
       "1995-01-02  3.397685  0.000000  28.742493\n",
       "1995-01-03  3.092484  0.000000  29.230500\n",
       "1995-01-04  3.917221  0.000000  28.689178\n",
       "1995-01-05  4.295576  0.019365  28.674103"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print P Ep T timeseries for catchment [0] in catch_id_list\n",
    "catch_id = catch_id_list[0]\n",
    "f = glob.glob(f'{fol_out}/daily/{catch_id}*.csv')\n",
    "print(f)\n",
    "c = pd.read_csv(f[0], index_col=0)\n",
    "c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a857b975-7dfe-44a0-a2bd-0042d6ad7084",
   "metadata": {},
   "source": [
    "## CHIRPS AND CRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a074dda-fa21-425a-aded-945df12dd902",
   "metadata": {},
   "source": [
    "### run grid to catchments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e2fb27f-0af4-4fd4-ae9e-0f604f254b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories \n",
    "nc_cru = f'{work_dir}/data/cru_p/cru_ts4.06_1961_2010_pre.nc' # dir of netcdf forcing files\n",
    "out_dir = f'{work_dir}/output/forcing_timeseries/cru_p/area_weighted' # output dir\n",
    "operator = 'mean'\n",
    "\n",
    "shape_dir = Path(f'{work_dir}/output/selected_shapes/')\n",
    "shapefile_list = glob.glob(f'{shape_dir}/*.shp')[0:5]\n",
    "\n",
    "netcdf_list = [nc_cru]*len(shapefile_list)\n",
    "output_dir_list = [out_dir]*len(shapefile_list)\n",
    "operator_list = [operator]*len(shapefile_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a937e67d-0017-49d4-87bf-77771a541ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run function parallel\n",
    "run_cru_function_parallel(shapefile_list, netcdf_list, operator_list, output_dir_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887ac3e4-f594-4959-bcc8-21eefffc615a",
   "metadata": {},
   "source": [
    "### process timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1a46aa3-57d1-4893-aff2-4fee05a515e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_id_list = np.loadtxt(f'{work_dir}/output/gsim_aus_catch_id_list_lo_sel.txt',dtype=str)[:]\n",
    "regrid_type='area_weighted'\n",
    "\n",
    "work_dir_list = [work_dir]*len(catch_id_list)\n",
    "regrid_type_list = [regrid_type]*len(catch_id_list)\n",
    "\n",
    "run_cru_processing_function_parallel(catch_id_list,work_dir_list,regrid_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69f1038a-3d93-479b-863e-ec59cf586bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_id_list = np.loadtxt(f'{work_dir}/output/gsim_aus_catch_id_list_lo_sel.txt',dtype=str)[:]\n",
    "regrid_type='nearest_neighbour'\n",
    "\n",
    "work_dir_list = [work_dir]*len(catch_id_list)\n",
    "regrid_type_list = [regrid_type]*len(catch_id_list)\n",
    "\n",
    "run_cru_processing_function_parallel(catch_id_list,work_dir_list,regrid_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bcff616-4964-4ef0-b1cb-c16289f3069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge cru mean values in dataframe - area weighted\n",
    "files = glob.glob(f\"{work_dir}/output/forcing_timeseries/cru_p/area_weighted/processed/mean/*\")[:]\n",
    "li=[] #empty list\n",
    "for filename in files:\n",
    "    df = pd.read_csv(filename, index_col=0) #read file as dataframe\n",
    "    f1 = filename.split('mean/')[1]\n",
    "    f2 = f1.split('_1961')[0]\n",
    "    d = pd.DataFrame(index=[f2],columns=['cru_mean_p_aw'])\n",
    "    d['cru_mean_p_aw'] = df['0'].values\n",
    "    li.append(d) #append file to list\n",
    "aw = pd.concat(li, axis=0) #concatenate lists\n",
    "aw.to_csv(f\"{work_dir}/output/forcing_timeseries/cru_p/mean_p_area_weighted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bed16c8f-9ae6-48b4-bd92-c68356489fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge cru mean values in dataframe - nearest neighbour\n",
    "files = glob.glob(f\"{work_dir}/output/forcing_timeseries/cru_p/nearest_neighbour/processed/mean/*\")[:]\n",
    "li=[] #empty list\n",
    "for filename in files:\n",
    "    df = pd.read_csv(filename, index_col=0) #read file as dataframe\n",
    "    f1 = filename.split('mean/')[1]\n",
    "    f2 = f1.split('_1961')[0]\n",
    "    d = pd.DataFrame(index=[f2],columns=['cru_mean_p_nn'])\n",
    "    d['cru_mean_p_nn'] = df['0'].values\n",
    "    li.append(d) #append file to list\n",
    "nn = pd.concat(li, axis=0) #concatenate lists\n",
    "nn.to_csv(f\"{work_dir}/output/forcing_timeseries/cru_p/mean_p_nearest_neighbour.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ed2a951-032d-4c89-9d6e-9603a3cf7dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = pd.concat([aw,nn],axis=1)\n",
    "cb.to_csv(f\"{work_dir}/output/forcing_timeseries/cru_p/mean_p.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff9c63ba-a6c1-4016-9ae7-b4810a8ec8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cru_mean_p_aw</th>\n",
       "      <th>cru_mean_p_nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ch_0000103</th>\n",
       "      <td>3.898726</td>\n",
       "      <td>3.890731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us_0002154</th>\n",
       "      <td>3.928862</td>\n",
       "      <td>3.923121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_0003144</th>\n",
       "      <td>1.139313</td>\n",
       "      <td>1.139023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us_0000227</th>\n",
       "      <td>3.305487</td>\n",
       "      <td>3.305487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de_0000803</th>\n",
       "      <td>1.962505</td>\n",
       "      <td>1.962505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_0000756</th>\n",
       "      <td>2.681718</td>\n",
       "      <td>2.672363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_0000894</th>\n",
       "      <td>2.470836</td>\n",
       "      <td>2.466738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>br_0003043</th>\n",
       "      <td>5.130479</td>\n",
       "      <td>4.980619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_0001736</th>\n",
       "      <td>4.072753</td>\n",
       "      <td>4.085046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>br_0001346</th>\n",
       "      <td>3.900797</td>\n",
       "      <td>3.864908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8658 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            cru_mean_p_aw  cru_mean_p_nn\n",
       "ch_0000103       3.898726       3.890731\n",
       "us_0002154       3.928862       3.923121\n",
       "ca_0003144       1.139313       1.139023\n",
       "us_0000227       3.305487       3.305487\n",
       "de_0000803       1.962505       1.962505\n",
       "...                   ...            ...\n",
       "ca_0000756       2.681718       2.672363\n",
       "fr_0000894       2.470836       2.466738\n",
       "br_0003043       5.130479       4.980619\n",
       "ca_0001736       4.072753       4.085046\n",
       "br_0001346       3.900797       3.864908\n",
       "\n",
       "[8658 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0eddf0-3110-4dc9-aaa7-ebc91a63e10f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56955f6-f818-4104-bbc1-0b20aea533dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0373427a-087a-4b19-8189-29a8fdca3716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db41799-f7f9-4974-8d9d-3f08e09f3232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHIRPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42e527a0-3649-4d9d-8866-5a8866509036",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_chirps = f'{work_dir}/data/chirps_p/chirps-v2.0.1981.days_p01.nc' # dir of netcdf forcing files\n",
    "out_dir = f'{work_dir}/output/forcing_timeseries/chirps_p/area_weighted' # output dir\n",
    "operator = 'mean'\n",
    "\n",
    "shape_dir = Path(f'{work_dir}/output/selected_shapes/')\n",
    "shapefile_list = glob.glob(f'{shape_dir}/*.shp')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d278eed-9c27-4282-b0a0-6a3040c636f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "regrid_first=False #resolution is 0.05 degree, so very high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3330c52d-5b65-4895-b8e7-2ed43d710613",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_netcdf = nc_chirps\n",
    "catchment_shapefile = shapefile_list\n",
    "statistical_operator='mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e13cd57e-8136-4b87-ba2a-64e18178552b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/fransjevanoors/global_sr/data/chirps_p/chirps-v2.0.1981.days_p01.nc'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catchment_netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9e8b8f5-8156-4bda-8d4e-72efdede6264",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "coordinate's range greater than coordinate's unit's modulus",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2949279/1284619814.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mcube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim_coords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguess_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# From cube extract shapefile shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mcube\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcube\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatchment_shapefile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"contains\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#use all grid cells that lie >50% inside the catchment shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Calculate area weighted statistics of extracted grid cells (inside catchment shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/sr_env/lib/python3.9/site-packages/esmvalcore/preprocessor/_area.py\u001b[0m in \u001b[0;36mextract_shape\u001b[0;34m(cube, shapefile, method, crop, decomposed, ids)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             )\n\u001b[0;32m--> 634\u001b[0;31m             cube = _crop_cube(cube,\n\u001b[0m\u001b[1;32m    635\u001b[0m                               \u001b[0mstart_longitude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlon_min\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                               \u001b[0mstart_latitude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlat_min\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/sr_env/lib/python3.9/site-packages/esmvalcore/preprocessor/_area.py\u001b[0m in \u001b[0;36m_crop_cube\u001b[0;34m(cube, start_longitude, start_latitude, end_longitude, end_latitude, cmor_coords)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend_latitude\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m90.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0mend_latitude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m90.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         cube = extract_region(cube, start_longitude, end_longitude,\n\u001b[0m\u001b[1;32m    390\u001b[0m                               start_latitude, end_latitude)\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcube\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/sr_env/lib/python3.9/site-packages/esmvalcore/preprocessor/_area.py\u001b[0m in \u001b[0;36mextract_region\u001b[0;34m(cube, start_longitude, end_longitude, start_latitude, end_latitude)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# To check only the center, ignore_bounds must be set to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# True (default) is False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         region_subset = cube.intersection(\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mlongitude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_longitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_longitude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mlatitude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_latitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_latitude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/sr_env/lib/python3.9/site-packages/iris/cube.py\u001b[0m in \u001b[0;36mintersection\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2536\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intersect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_bounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2538\u001b[0;31m             result = result._intersect(\n\u001b[0m\u001b[1;32m   2539\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_bounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m             )\n",
      "\u001b[0;32m~/.conda/envs/sr_env/lib/python3.9/site-packages/iris/cube.py\u001b[0m in \u001b[0;36m_intersect\u001b[0;34m(self, name_or_coord, minimum, maximum, min_inclusive, max_inclusive, ignore_bounds)\u001b[0m\n\u001b[1;32m   2562\u001b[0m                 \u001b[0;34m\"coordinate units with no modulus are not yet\"\u001b[0m \u001b[0;34m\" supported\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m             )\n\u001b[0;32m-> 2564\u001b[0;31m         subsets, points, bounds = self._intersect_modulus(\n\u001b[0m\u001b[1;32m   2565\u001b[0m             \u001b[0mcoord\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m             \u001b[0mminimum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/sr_env/lib/python3.9/site-packages/iris/cube.py\u001b[0m in \u001b[0;36m_intersect_modulus\u001b[0;34m(self, coord, minimum, maximum, min_inclusive, max_inclusive, ignore_bounds)\u001b[0m\n\u001b[1;32m   2760\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodulus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2762\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2763\u001b[0m                 \u001b[0;34m\"coordinate's range greater than coordinate's\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2764\u001b[0m                 \u001b[0;34m\" unit's modulus\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: coordinate's range greater than coordinate's unit's modulus"
     ]
    }
   ],
   "source": [
    "# Load iris cube of netcdf\n",
    "cube = iris.load_cube(catchment_netcdf)\n",
    "# cube.dim_coords[1].guess_bounds()\n",
    "# cube.dim_coords[2].guess_bounds()\n",
    "\n",
    "# extract dates of netcdf timeseries to be used as filename\n",
    "time_start,time_end = cube.coord('time')[0],cube.coord('time')[-1]\n",
    "point_start, point_end = time_start.points, time_end.points\n",
    "unit = time_start.units\n",
    "l = unit.num2date(0)\n",
    "d = datetime(year=l.year, month=l.month, day=l.day)\n",
    "date_start, date_end = d + timedelta(days=int(point_start[0])), d + timedelta(days=int(point_end[0]))\n",
    "y_start, y_end = date_start.year, date_end.year\n",
    "\n",
    "# Create target grid and regrid cube\n",
    "if regrid_first is True:\n",
    "    target_cube = regridding_target_cube(catchment_shapefile, grid_resolution, buffer=1) #create the regrid target cube\n",
    "    # cube = preprocessor.regrid(cube, target_cube, scheme=\"area_weighted\") #regrid the netcdf file (conservative) to a higher resolution\n",
    "    cube = preprocessor.regrid(cube, target_cube, scheme=\"nearest\") #regrid the netcdf file (nearest neighbour) to a higher resolution\n",
    "\n",
    "cube.dim_coords[1].guess_bounds()\n",
    "cube.dim_coords[2].guess_bounds()\n",
    "# From cube extract shapefile shape\n",
    "cube = preprocessor.extract_shape(cube, catchment_shapefile, method=\"contains\") #use all grid cells that lie >50% inside the catchment shape\n",
    "\n",
    "# Calculate area weighted statistics of extracted grid cells (inside catchment shape)\n",
    "cube_stats = preprocessor.area_statistics(cube, statistical_operator)\n",
    "\n",
    "# Convert cube to dataframe\n",
    "df = iris.pandas.as_data_frame(cube_stats)\n",
    "\n",
    "# Change column names of timeseries dataframe\n",
    "df = df.reset_index()\n",
    "df = df.set_axis([\"time\", cube_stats.name()], axis=1)\n",
    "\n",
    "dates = pd.date_range(date_start,date_end + timedelta(days=31),freq='M')\n",
    "df.index = dates\n",
    "df = df.drop(columns='time')\n",
    "df.precipitation = df.precipitation/df.index.days_in_month\n",
    "\n",
    "var='p'\n",
    "# Write csv as output\n",
    "df.to_csv(f\"{output_dir}/{Path(catchment_shapefile).name.split('.')[0]}_{var}_{statistical_operator}_{y_start}_{y_end}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39f2b887-8579-43ac-8bcc-cb37ee71516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris cube of netcdf\n",
    "cube = iris.load_cube(catchment_netcdf)\n",
    "# cube.dim_coords[1].guess_bounds()\n",
    "# cube.dim_coords[2].guess_bounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1028a84-15c1-427c-952f-7324dc54fe26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  a.iris {\n",
       "      text-decoration: none !important;\n",
       "  }\n",
       "  table.iris {\n",
       "      white-space: pre;\n",
       "      border: 1px solid;\n",
       "      border-color: #9c9c9c;\n",
       "      font-family: monaco, monospace;\n",
       "  }\n",
       "  th.iris {\n",
       "      background: #303f3f;\n",
       "      color: #e0e0e0;\n",
       "      border-left: 1px solid;\n",
       "      border-color: #9c9c9c;\n",
       "      font-size: 1.05em;\n",
       "      min-width: 50px;\n",
       "      max-width: 125px;\n",
       "  }\n",
       "  tr.iris :first-child {\n",
       "      border-right: 1px solid #9c9c9c !important;\n",
       "  }\n",
       "  td.iris-title {\n",
       "      background: #d5dcdf;\n",
       "      border-top: 1px solid #9c9c9c;\n",
       "      font-weight: bold;\n",
       "  }\n",
       "  .iris-word-cell {\n",
       "      text-align: left !important;\n",
       "      white-space: pre;\n",
       "  }\n",
       "  .iris-subheading-cell {\n",
       "      padding-left: 2em !important;\n",
       "  }\n",
       "  .iris-inclusion-cell {\n",
       "      padding-right: 1em !important;\n",
       "  }\n",
       "  .iris-panel-body {\n",
       "      padding-top: 0px;\n",
       "  }\n",
       "  .iris-panel-title {\n",
       "      padding-left: 3em;\n",
       "  }\n",
       "  .iris-panel-title {\n",
       "      margin-top: 7px;\n",
       "  }\n",
       "</style>\n",
       "<table class=\"iris\" id=\"23454223076656\">\n",
       "    <tr class=\"iris\">\n",
       "<th class=\"iris iris-word-cell\">Climate Hazards Group Infrared Precipitation With Stations (mm/day)</th>\n",
       "<th class=\"iris iris-word-cell\">time</th>\n",
       "<th class=\"iris iris-word-cell\">latitude</th>\n",
       "<th class=\"iris iris-word-cell\">longitude</th>\n",
       "</tr>\n",
       "    <tr class=\"iris\">\n",
       "<td class=\"iris-word-cell iris-subheading-cell\">Shape</td>\n",
       "<td class=\"iris iris-inclusion-cell\">365</td>\n",
       "<td class=\"iris iris-inclusion-cell\">1800</td>\n",
       "<td class=\"iris iris-inclusion-cell\">3600</td>\n",
       "</tr>\n",
       "    <tr class=\"iris\">\n",
       "    <td class=\"iris-title iris-word-cell\">Dimension coordinates</td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\ttime</td>\n",
       "    <td class=\"iris-inclusion-cell\">x</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tlatitude</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">x</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tlongitude</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">x</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-title iris-word-cell\">Attributes</td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tCDI                                                           Climate Data Interface version 1.9.10 (https</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"3\">/mpimet.mpg.de/cdi)</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tCDO                                                           Climate Data Operators version 1.9.10 (https</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"3\">/mpimet.mpg.de/cdo)<br>Conventions                                                   CF-1.6<br>acknowledgements                                              The Climate Hazards Group InfraRed Precipitation with Stations development...<br>comments                                                       time variable denotes the first day of the given day.<br>creator_email                                                 pete@geog.ucsb.edu<br>creator_name                                                  Pete Peterson<br>date_created                                                  2015-11-20</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tdocumentation                                                 http</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"3\">/pubs.usgs.gov/ds/832/</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tfaq                                                           http</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"3\">/chg-wiki.geog.ucsb.edu/wiki/CHIRPS_FAQ</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tftp_url                                                       ftp</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"3\">/chg-ftpout.geog.ucsb.edu/pub/org/chg/products/CHIRPS-latest/<br>geostatial_lat_max                                            50.0<br>geostatial_lat_min                                            -50.0<br>geostatial_lon_max                                            180.0<br>geostatial_lon_min                                            -180.0</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\thistory                                                       &#x27;Wed Mar 01 13</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"3\">0:42 2023: cdo remapcon,r3600x1800 chirps-v2.0.1981.days_p05.nc...<br>institution                                                   Climate Hazards Group.  University of California at Santa Barbara<br>invalid_standard_name                                         convective precipitation rate<br>reference                                                     Funk, C.C., Peterson, P.J., Landsfeld, M.F., Pedreros, D.H., Verdin, J.P.,...<br>time_step                                                     day<br>title                                                         CHIRPS Version 2.0<br>version                                                       Version 2.0</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\twebsite                                                       http</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"3\">/chg.geog.ucsb.edu/data/chirps/index.html</td>\n",
       "</tr>\n",
       "</table>\n",
       "        "
      ],
      "text/plain": [
       "<iris 'Cube' of Climate Hazards group InfraRed Precipitation with Stations / (mm/day) (time: 365; latitude: 1800; longitude: 3600)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59ac7ba6-9a63-4715-897c-7c51a06c97bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DimCoord(array([0.000e+00, 1.000e-01, 2.000e-01, ..., 3.597e+02, 3.598e+02,\n",
       "       3.599e+02]), bounds=array([[-5.0000e-02,  5.0000e-02],\n",
       "       [ 5.0000e-02,  1.5000e-01],\n",
       "       [ 1.5000e-01,  2.5000e-01],\n",
       "       ...,\n",
       "       [ 3.5965e+02,  3.5975e+02],\n",
       "       [ 3.5975e+02,  3.5985e+02],\n",
       "       [ 3.5985e+02,  3.5995e+02]]), standard_name='longitude', units=Unit('degrees'), long_name='longitude', var_name='lon')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube.coord(\"longitude\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a98cb2b8-46d2-48c8-b2fb-13f0093b9376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DimCoord(array([-89.95, -89.85, -89.75, ...,  89.75,  89.85,  89.95]), bounds=array([[-90. , -89.9],\n",
       "       [-89.9, -89.8],\n",
       "       [-89.8, -89.7],\n",
       "       ...,\n",
       "       [ 89.7,  89.8],\n",
       "       [ 89.8,  89.9],\n",
       "       [ 89.9,  90. ]]), standard_name='latitude', units=Unit('degrees'), long_name='latitude', var_name='lat')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube.coord(\"latitude\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee1a67-b986-4ba2-bcc1-7e92953abdab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cd4db8-5b3b-4554-881e-8f065870c050",
   "metadata": {},
   "outputs": [],
   "source": [
    "## grid to catchments for cru precipitation\n",
    "def area_weighted_shapefile_rasterstats_cru(\n",
    "    catchment_shapefile,\n",
    "    catchment_netcdf,\n",
    "    statistical_operator,\n",
    "    output_dir,\n",
    "    output_csv=True,\n",
    "    return_cube=False,\n",
    "    regrid_first=True,\n",
    "    grid_resolution=0.1\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate area weighted zonal statistics of netcdfs using a shapefile to extract netcdf data.\n",
    "\n",
    "    catchment_shapefile:  str, catchment shapefile\n",
    "    catchment_netcdf:     str, netcdf file\n",
    "    statistical_operator: str, (mean, median (NOT area weighted), sum, variance, min, max, rms)\n",
    "    - https://docs.esmvaltool.org/projects/esmvalcore/en/latest/api/esmvalcore.preprocessor.html#esmvalcore.preprocessor.area_statistics\n",
    "    output_csv:          bool, True stores csv output and False stores netcdf output\n",
    "    regrid_first:        bool, True regrid cube first before extracting shape, False do not regrid first\n",
    "    grid_resolution:    float, grid cell size of target cube in degrees\n",
    "    Returns: iris cube, stores .csv file or .nc file\n",
    "    \"\"\"\n",
    "\n",
    "    # Load iris cube of netcdf\n",
    "    cube = iris.load_cube(catchment_netcdf)\n",
    "    cube.dim_coords[1].guess_bounds()\n",
    "    cube.dim_coords[2].guess_bounds()\n",
    "\n",
    "    # extract dates of netcdf timeseries to be used as filename\n",
    "    time_start,time_end = cube.coord('time')[0],cube.coord('time')[-1]\n",
    "    point_start, point_end = time_start.points, time_end.points\n",
    "    unit = time_start.units\n",
    "    l = unit.num2date(0)\n",
    "    d = datetime(year=l.year, month=l.month, day=l.day)\n",
    "    date_start, date_end = d + timedelta(days=int(point_start[0])), d + timedelta(days=int(point_end[0]))\n",
    "    y_start, y_end = date_start.year, date_end.year\n",
    "\n",
    "    # Create target grid and regrid cube\n",
    "    if regrid_first is True:\n",
    "        target_cube = regridding_target_cube(catchment_shapefile, grid_resolution, buffer=1) #create the regrid target cube\n",
    "        # cube = preprocessor.regrid(cube, target_cube, scheme=\"area_weighted\") #regrid the netcdf file (conservative) to a higher resolution\n",
    "        cube = preprocessor.regrid(cube, target_cube, scheme=\"nearest\") #regrid the netcdf file (nearest neighbour) to a higher resolution\n",
    "\n",
    "    # From cube extract shapefile shape\n",
    "    cube = preprocessor.extract_shape(cube, catchment_shapefile, method=\"contains\") #use all grid cells that lie >50% inside the catchment shape\n",
    "\n",
    "    # Calculate area weighted statistics of extracted grid cells (inside catchment shape)\n",
    "    cube_stats = preprocessor.area_statistics(cube, statistical_operator)\n",
    "\n",
    "    # Convert cube to dataframe\n",
    "    df = iris.pandas.as_data_frame(cube_stats)\n",
    "\n",
    "    # Change column names of timeseries dataframe\n",
    "    df = df.reset_index()\n",
    "    df = df.set_axis([\"time\", cube_stats.name()], axis=1)\n",
    "\n",
    "    dates = pd.date_range(date_start,date_end + timedelta(days=31),freq='M')\n",
    "    df.index = dates\n",
    "    df = df.drop(columns='time')\n",
    "    df.precipitation = df.precipitation/df.index.days_in_month\n",
    "\n",
    "    var='p'\n",
    "    # Write csv as output\n",
    "    df.to_csv(f\"{output_dir}/{Path(catchment_shapefile).name.split('.')[0]}_{var}_{statistical_operator}_{y_start}_{y_end}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1759a65a-3c5d-4bf6-8da8-3e2c594c28f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c067afa-0692-49d4-baf6-ba0e0125b683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548b2e76-3976-44b8-8af9-b2b40651c593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4803ceca-cf0b-4437-aa63-c7171b25d62e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7573da75-58cf-4369-9527-8f51d9e869e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
