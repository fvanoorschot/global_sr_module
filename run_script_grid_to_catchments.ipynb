{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62e3f38f-c900-4727-a9e1-2735ae539100",
   "metadata": {},
   "source": [
    "# Run script - gridded data to catchment timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ac8f8-f3cb-4841-a27f-c6ce951f46b9",
   "metadata": {},
   "source": [
    "In this script we extract catchment timeseries of precipitation, potential evaporation and temperature from global gridded products. \n",
    "\n",
    "This scripts only works in the conda environment **sr_env**. In this environment all required packages are available. If you have **not** installed and activated this environment before opening this script, you should check the installation section in the *README* file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f072c26-9428-4158-b011-45a7bf495721",
   "metadata": {},
   "source": [
    "### 1. Getting started\n",
    "First, import all the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12476d9c-f4d9-41d7-889e-4e84ec7ee35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import iris\n",
    "import iris.pandas\n",
    "import numpy as np\n",
    "from esmvalcore import preprocessor\n",
    "from iris.coords import DimCoord\n",
    "from iris.cube import Cube\n",
    "from pathos.threading import ThreadPool as Pool\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d94080-a55a-49dc-bfd7-09ef86d1ffa2",
   "metadata": {},
   "source": [
    "Here we import all the python functions defined in the scripts *f_grid_to_catchments.py*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b053a7a-23b8-434d-ae1d-19888e5f5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python functions\n",
    "from f_grid_to_catchments import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a9ed88-646a-4209-b0a1-5e01426119ee",
   "metadata": {},
   "source": [
    "### 2. Define working directory\n",
    "Here we define the working directory, where all the scripts and data are saved. Make sure that you generate within this working directory the following subdirectories with the data:\\\n",
    "/work_dir/data/forcing/*netcdf forcing files*\\\n",
    "/work_dir/data/shapes/*catchment shapefiles*\\\n",
    "/work_dir/data/gsim_discharge/*gsim discharge timeseries*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48e094df-ec04-4c83-a259-9a4395300ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your working directory\n",
    "work_dir=Path(\"/work/users/vanoorschot/fransje/scripts/GLOBAL_SR/global_sr_module\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfb49e0-e014-45eb-ac49-200b78d4c9b5",
   "metadata": {},
   "source": [
    "### 3. From gridded data to catchment timeseries\n",
    "We don't have data on precipitation, potential evaporation and temperature at the catchment scale. Therefore, we use global gridded products of these parameters (there are a lot of possibilities which data to use). For doing analyses at the catchment scale, we need to convert these gridded products into catchment timeseries.\n",
    "To do this, we calculate the mean parameter values of the gridcells that fall within the catchment shapes. The procedure is defined by the functions in the *f_grid_to_catchments.py* file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a121ca04-36e3-45c4-a687-0de3848a696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output directories\n",
    "if not os.path.exists(f'{work_dir}/output/forcing_timeseries/raw'):\n",
    "    os.makedirs(f'{work_dir}/output/forcing_timeseries/raw')\n",
    "if not os.path.exists(f'{work_dir}/output/forcing_timeseries/processed'):\n",
    "    os.makedirs(f'{work_dir}/output/forcing_timeseries/processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "effae491-88d1-4129-9c96-be010c08048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories \n",
    "SHAPE_DIR = Path(f'{work_dir}/data/shapes/') # dir of shapefiles\n",
    "NC4_DIR = Path(f'{work_dir}/data/forcing/') # dir of netcdf forcing files\n",
    "OUT_DIR = Path(f'{work_dir}/output/forcing_timeseries/raw') # output dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25df1f20-ffb8-4977-a5d3-eb8f6823f620",
   "metadata": {},
   "source": [
    "The conversion from grid to catchment is computationally expensive. Therefore, we run this conversion for all catchments in parallel using the python function *pathos threadpool* (https://pathos.readthedocs.io/en/latest/pathos.html#module-pathos.threading).\n",
    "With the *construct_lists_for_parallel_function* function from *f_grid_to_catchments.py* we create lists that contain all combinations of shapefile, netcdf-file and output-directory. OPERATOR LIST NOT NEEDED?. These lists are the input for the *run_function_parallel* function from *f_grid_to_catchments.py*, which returns timeseries of the catchment mean values of precipitation (P), potential evaporation (Ep) and  temperature (T). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "231a7885-48c3-47c2-af34-5d3e682a8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct lists for parallel run\n",
    "(shapefile_list, netcdf_list, operator_list, output_dir_list) = construct_lists_for_parallel_function(NC4_DIR, SHAPE_DIR, OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e28d5df1-69e7-4bb1-ac8a-ced200967d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run function parallel\n",
    "run_function_parallel(shapefile_list, netcdf_list, operator_list, output_dir_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec7d309-611d-4df3-ad73-778db1361987",
   "metadata": {},
   "source": [
    "The output of the *run_function_parallel* function contains daily timeseries of P, Ep and T for all catchments. Here we postprocess these data to get dataframes containing Ep, P and T together with daily, monthly and yearly timeseries, climatology and mean values (stored as *csv* files). This postprocessing is done in the *process_forcing_timeseries* function defined in *f_grid_to_catchments.py*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e2bc092-97f9-4cec-bd0f-97aba6990b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input directory\n",
    "fol_in=f'{work_dir}/output/forcing_timeseries/raw'\n",
    "# define output directory\n",
    "fol_out=f'{work_dir}/output/forcing_timeseries/processed'\n",
    "\n",
    "# get catch_id_list\n",
    "catch_id_list = np.genfromtxt(f'{work_dir}/output/catch_id_list.txt',dtype='str')\n",
    "\n",
    "# define variables\n",
    "var = ['Ep','P','T']\n",
    "\n",
    "# run process_forcing_timeseries (defined in f_grid_to_catchments.py) for all catchments in catch_id_list\n",
    "for catch_id in catch_id_list:\n",
    "    process_forcing_timeseries(catch_id,fol_in,fol_out,var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380c5ac6-dcae-4366-9eb0-b25f8d2f0405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
